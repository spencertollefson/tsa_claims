{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pyspark\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import tabula\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, cross_validate \\\n",
    "                                    ,cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create passengers df\n",
    "passengers = tabula.read_pdf('./data/raw/passengers/usa2017enplanements.pdf',multiple_tables=True, pages='all', guess=False, lattice=True)\n",
    "df = pd.concat(passengers, axis=0, ignore_index=True)\n",
    "df = df[[3, 8, 9, 10]]\n",
    "df = df[1:]\n",
    "col = {3: 'airport_code', 8: 'cy17', 9: 'cy16', 10:'perc_change'}\n",
    "df.rename(columns=col, inplace=True)\n",
    "\n",
    "df = df[~df.airport_code.isin(['Locid'])]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.cy17 = df.cy17.str.replace(',','')\n",
    "df.cy16 = df.cy16.str.replace(',','')\n",
    "df.cy17 = df.cy17.astype('int64')\n",
    "df.cy16 = df.cy16.astype('int64')\n",
    "\n",
    "df.perc_change = df.perc_change.str.replace('%','')\n",
    "df.perc_change = df.perc_change.astype('float64')\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/clean/usa2016-17-enplanements.csv')\n",
    "# df.to_pickle('./data/clean/usa2016-17-enplanements.pkl')\n",
    "df= pd.read_pickle('./data/clean/usa2016-17-enplanements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05868591831574753"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cy17.iloc[0] / df.cy17.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797069865424873"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cy17.iloc[:40].sum() / df.cy17.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>cy17</th>\n",
       "      <th>cy16</th>\n",
       "      <th>perc_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RSW</td>\n",
       "      <td>4364217</td>\n",
       "      <td>4239261</td>\n",
       "      <td>2.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airport     cy17     cy16  perc_change\n",
       "47     RSW  4364217  4239261        2.950"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.airport == 'RSW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bernoulliNB_12.04.2018.joblib\n",
      "catboost_12.05.2018.joblib\n",
      "catboost_new_12.05.2018.joblib\n",
      "catboost_search_12.05.2018.joblib\n",
      "extratrees_12.04.2018.joblib\n",
      "gradboost_12.04.2018.joblib\n",
      "logit_12.04.2018.joblib\n",
      "multinomialNB_12.04.2018.joblib\n",
      "preliminary\n",
      "rf_12.04_feature_importance_list\n",
      "rf_months_12.03.2018\n",
      "rf_months_12.03.2018.joblib\n",
      "rf_subset_airports_airlines_12.04.2018.joblib\n",
      "supportvector_12.04.2018.joblib\n",
      "transformers\n",
      "xgb_12.05.2018.joblib\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(open('./models/catboost_new_12.05.2018.joblib', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example = {\n",
    "  'airport_code': 'SEA',  # str\n",
    "  'airline': 'Emirates',    # str\n",
    "  'claim_type': 'PropertyLoss',    # str\n",
    "  'claim_site': 'Checkpoint',  # str\n",
    "  'item_category': 'Clothing',  # str\n",
    "  'num_items_or_incidents_claimed': 1,  # int\n",
    "  'days_waited_to_file_claim': 7,  # int\n",
    "  'Month_received': '1'  # int (1-12)\n",
    "}\n",
    "\n",
    "\n",
    "def make_prediction(features):\n",
    "    '''\n",
    "    :param features: dictionary like 'example' above\n",
    "    :return: 2 pair dict of binary outcome (compensate and not compensate) and the probablity\n",
    "    '''\n",
    "    X = pd.DataFrame(data=features, index=[0])\n",
    "\n",
    "    categorical = ['airport_code', 'airline', 'claim_type', 'claim_site', 'Month_received']\n",
    "    continuous = ['days_waited_to_file_claim', 'num_items_or_incidents_claimed']\n",
    "\n",
    "    trans_dir = './stat_models/transformers'\n",
    "    enc = joblib.load(f'{trans_dir}/onehotencode.joblib')\n",
    "    onehotarray = enc.transform(X[categorical])\n",
    "\n",
    "    ss = joblib.load(f'{trans_dir}/standardscaler.joblib')\n",
    "    continuousarray = ss.transform(X[continuous])\n",
    "\n",
    "    mlb = joblib.load(f'{trans_dir}/item_category.joblib')\n",
    "    onehot_itemcategories = mlb.transform(X['item_category'].str.replace(' ', '').str.split(pat=';'))\n",
    "\n",
    "    X = np.concatenate((onehotarray, continuousarray, onehot_itemcategories), axis=1)\n",
    "\n",
    "    prob_receive_compensation = model.predict_proba(X)[0, 1]\n",
    "\n",
    "    result = {\n",
    "        'compensation': int(prob_receive_compensation > 0.5),\n",
    "        'prob_receive_compensation': prob_receive_compensation\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './stat_models/transformers/onehotencode.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0f1989253d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-175ce2c637de>\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrans_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./stat_models/transformers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{trans_dir}/onehotencode.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0monehotarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './stat_models/transformers/onehotencode.joblib'"
     ]
    }
   ],
   "source": [
    "make_prediction(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
