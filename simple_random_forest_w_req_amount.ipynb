{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Should I calculate business days since incident? or Total days?\n",
    "* How to do timeseries?\n",
    "  * Only predict a date based on the info that's happened BEFORE it?\n",
    "  * Book by week? exact day of year? month?\n",
    " ---\n",
    "* Could I make an EITHER/OR case?\n",
    "  * First do a classifier for Compensate or Deny. If compensate, then do a Regression for HOW MUCH they'll get back?\n",
    "  * I could also do models that ONLY take into account how much they asked for, IF I have enough data\n",
    "* Why is my RF 410 MB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st simple model, \"settle\" or \"compensate\" I got 68% ROC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Is it an issue with 370 airports and 170 airlines?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pyspark\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import tabula\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer, LabelBinarizer, MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, cross_validate \\\n",
    "                                    ,cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'models/preliminary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that does the cleaning if you pass the df\n",
    "\n",
    "def colnames_dt_drops_dtypes(df):\n",
    "    col_names = ['claim_number', 'date_received', 'incident_date', 'airport_code', 'airport_name',\n",
    "           'airline', 'claim_type', 'claim_site', 'item_category', 'close_amount', 'disposition']\n",
    "    df['date_received'] = pd.to_datetime(df['date_received'])\n",
    "    df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
    "    df = df[df['disposition'] != \"-\"]\n",
    "    df = df.dropna()\n",
    "    df['claim_number'] = df['claim_number'].astype('int64')\n",
    "    df['close_amount'] = df['close_amount'].astype('int64')\n",
    "    df['binary_disposition'] = df['disposition']\n",
    "    df['binary_disposition'] = df['binary_disposition'].where(df['binary_disposition'] == 'Deny', other='Compensate')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['claim_number', 'date_received', 'incident_date', 'airport_code', 'airport_name',\n",
    "           'airline', 'claim_type', 'claim_site', 'item_category', 'claim_amount', 'status', 'close_amount', 'disposition']\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('raw/claims-2002-2006.xls', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['claim_number', 'airport_name', \n",
    "                     #'binary_disposition',\n",
    "                     #'disposition', \n",
    "#                      'date_received', 'incident_date',\n",
    "              'status'\n",
    "                    ]\n",
    "                    , axis=1)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the 24 dates in date_received that happened after 2006\n",
    "df = df.drop(index=df.date_received.sort_values(ascending=False)[:23].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df['date_received'] = pd.to_datetime(df['date_received'])\n",
    "df['incident_date'] = df.incident_date.apply(lambda x: np.nan if type(x) != dt.datetime else x)\n",
    "df = df.dropna()\n",
    "df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
    "df = df[df['disposition'] != \"-\"]\n",
    "\n",
    "# df['claim_number'] = df['claim_number'].astype('int64')\n",
    "df['close_amount'] = df['close_amount'].astype('int64')\n",
    "df['claim_amount'] = df['claim_amount'].astype('int64')\n",
    "\n",
    "df['binary_disposition'] = df['disposition']\n",
    "df['binary_disposition'] = df['binary_disposition'].where(df['binary_disposition'] == 'Deny', other='Compensate')\n",
    "\n",
    "# Time calculation\n",
    "wait_period = df.date_received - df.incident_date\n",
    "df['days_until_filed_claim'] = wait_period.dt.days\n",
    "\n",
    "# Drop days where the 'date_received\" was reported before 'incident_date'\n",
    "df = df[df.days_until_filed_claim >= 0]\n",
    "\n",
    "# Change some text to make it more human readable\n",
    "df.claim_site[df.claim_site == '-'] = 'Unknown'\n",
    "df.claim_type[df.claim_type == '-'] = 'Unknown'\n",
    "\n",
    "# Decrease item_category to the top leel categories only (only 27 instead of 300+ of them)\n",
    "df['item_category'] = df['item_category'].str.replace(';.+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>incident_date</th>\n",
       "      <th>airport_code</th>\n",
       "      <th>airline</th>\n",
       "      <th>claim_type</th>\n",
       "      <th>claim_site</th>\n",
       "      <th>item_category</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>close_amount</th>\n",
       "      <th>disposition</th>\n",
       "      <th>binary_disposition</th>\n",
       "      <th>days_until_filed_claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>2003-02-21</td>\n",
       "      <td>2003-01-08</td>\n",
       "      <td>LAS</td>\n",
       "      <td>Southwest Airlines</td>\n",
       "      <td>Passenger Property Loss</td>\n",
       "      <td>Checked Baggage</td>\n",
       "      <td>Other</td>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "      <td>Deny</td>\n",
       "      <td>Deny</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36935</th>\n",
       "      <td>2004-06-03</td>\n",
       "      <td>2004-04-02</td>\n",
       "      <td>F</td>\n",
       "      <td>Northwest Airlines</td>\n",
       "      <td>Passenger Property Loss</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>45178</td>\n",
       "      <td>45178</td>\n",
       "      <td>Deny</td>\n",
       "      <td>Deny</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50725</th>\n",
       "      <td>2004-11-24</td>\n",
       "      <td>2003-12-27</td>\n",
       "      <td>HPN</td>\n",
       "      <td>USAir</td>\n",
       "      <td>Personal Injury</td>\n",
       "      <td>Checkpoint</td>\n",
       "      <td>Clothing - Shoes, belts, accessories, etc.</td>\n",
       "      <td>50150</td>\n",
       "      <td>20000</td>\n",
       "      <td>Settle</td>\n",
       "      <td>Compensate</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>2004-10-09</td>\n",
       "      <td>2004-09-02</td>\n",
       "      <td>LAX</td>\n",
       "      <td>USAir</td>\n",
       "      <td>Passenger Property Loss</td>\n",
       "      <td>Checked Baggage</td>\n",
       "      <td>Luggage (all types including footlockers)</td>\n",
       "      <td>14518</td>\n",
       "      <td>14518</td>\n",
       "      <td>Deny</td>\n",
       "      <td>Deny</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52575</th>\n",
       "      <td>2004-12-21</td>\n",
       "      <td>2004-10-08</td>\n",
       "      <td>CMH</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>Property Damage</td>\n",
       "      <td>Checked Baggage</td>\n",
       "      <td>Photographic Film</td>\n",
       "      <td>13060</td>\n",
       "      <td>13060</td>\n",
       "      <td>Approve in Full</td>\n",
       "      <td>Compensate</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_received incident_date airport_code             airline  \\\n",
       "2703     2003-02-21    2003-01-08          LAS  Southwest Airlines   \n",
       "36935    2004-06-03    2004-04-02            F  Northwest Airlines   \n",
       "50725    2004-11-24    2003-12-27          HPN               USAir   \n",
       "47057    2004-10-09    2004-09-02          LAX               USAir   \n",
       "52575    2004-12-21    2004-10-08          CMH   American Airlines   \n",
       "\n",
       "                    claim_type       claim_site  \\\n",
       "2703   Passenger Property Loss  Checked Baggage   \n",
       "36935  Passenger Property Loss            Other   \n",
       "50725          Personal Injury       Checkpoint   \n",
       "47057  Passenger Property Loss  Checked Baggage   \n",
       "52575          Property Damage  Checked Baggage   \n",
       "\n",
       "                                    item_category  claim_amount  close_amount  \\\n",
       "2703                                        Other        250000        250000   \n",
       "36935                                       Other         45178         45178   \n",
       "50725  Clothing - Shoes, belts, accessories, etc.         50150         20000   \n",
       "47057   Luggage (all types including footlockers)         14518         14518   \n",
       "52575                           Photographic Film         13060         13060   \n",
       "\n",
       "           disposition binary_disposition  days_until_filed_claim  \n",
       "2703              Deny               Deny                      44  \n",
       "36935             Deny               Deny                      62  \n",
       "50725           Settle         Compensate                     333  \n",
       "47057             Deny               Deny                      37  \n",
       "52575  Approve in Full         Compensate                      74  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='close_amount', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = df.drop(['claim_number', 'airport_name', \n",
    "                     #'binary_disposition',\n",
    "                     'disposition', \n",
    "                     'date_received', 'incident_date'\n",
    "                    ]\n",
    "                    , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([#'claim_number', 'airport_name', \n",
    "             'binary_disposition', 'disposition', \n",
    "             'date_received', 'incident_date',\n",
    "             'close_amount',\n",
    "            ]\n",
    "            , axis=1)\n",
    "y = df['binary_disposition'].apply(lambda x: 1 if x == 'Compensate' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['airport_code', 'airline', 'claim_type', 'claim_site', 'item_category']\n",
    "continuous =  ['claim_amount', 'days_until_filed_claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencer/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/spencer/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "onehotarray = enc.fit_transform(X[categorical])\n",
    "ss = StandardScaler()\n",
    "continuousarray = ss.fit_transform(X[continuous])\n",
    "X = np.concatenate((onehotarray, continuousarray), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863849896669834\n",
      "{'criterion': 'gini', 'n_estimators': 300}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "criterions = ['gini'] #, 'entropy']\n",
    "n_ests = [#100,\n",
    "          300]\n",
    "    \n",
    "param_grid = dict(criterion=criterions, n_estimators=n_ests)\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'models/preliminary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/preliminary/rf_num2_with_requested_amount_but_no_dates']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_rf.best_estimator_, f'{dir}/rf_num2_with_requested_amount_but_no_dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
